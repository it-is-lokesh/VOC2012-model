{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dateT = '01_26_23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = keras.utils.image_dataset_from_directory(\n",
    "    directory = '../../dataset',\n",
    "    validation_split=0.1,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    image_size = (128, 128),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = keras.utils.image_dataset_from_directory(\n",
    "    directory = '../../dataset',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    image_size = (128, 128),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_norm = train.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_norm = val.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Conv2D(8, kernel_size=(5,5), padding='valid', activation='relu', input_shape=(128,128,3)),\n",
    "    MaxPooling2D(pool_size=(2,2), padding='valid'),\n",
    "\n",
    "    # Conv2D(45, kernel_size=(5,5), padding='valid', activation='relu'),\n",
    "    # MaxPooling2D(pool_size=(2,2), padding='valid'),\n",
    "\n",
    "    # Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu'),\n",
    "    # MaxPooling2D(pool_size=(2,2), padding='valid'),\n",
    "    \n",
    "    # Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu'),\n",
    "    # MaxPooling2D(pool_size=(2,2), padding='valid'),\n",
    "\n",
    "    Flatten(),\n",
    "    # Dense(32, activation='relu'),\n",
    "    # Dense(64, activation='relu'),\n",
    "    Dense(20, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "\tdef on_epoch_end(self, epoch, logs={}):\n",
    "\t\tif(logs.get('accuracy') > 0.9):\n",
    "\t\t\tprint(logs)\n",
    "\t\t\tprint(\"\\nReached the required accuracy, so stopping training!!\")\n",
    "\t\t\tself.model.stop_training = True\n",
    "\n",
    "callback = myCallback()\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_norm, epochs=150, validation_data=val_norm, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Set the API key\u001b[39;00m\n\u001b[0;32m      3\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msk-JwaOErOL0VdsozBz1YLhT3BlbkFJue1AQJtg5lIsLaykjjhL\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "# Set the API key\n",
    "openai.api_key = \"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\"\n",
    "# Use the ChatGPT model to generate text\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"Hello, how are you today?\"\n",
    "completion = openai.Completion.create(engine=model_engine, prompt=prompt, max_tokens=1024, n=1,stop=None,temperature=0.7)\n",
    "message = completion.choices[0].text\n",
    "print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1016640dd660c0e0a8e8bdb127af68117ae230035cad3bd73da474f598195d09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
